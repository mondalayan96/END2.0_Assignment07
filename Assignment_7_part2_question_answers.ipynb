{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "END-Session-7.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ0GNTGwNoH1",
        "outputId": "f9321dbe-2a0e-486b-e6e6-a143e2267108"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.4)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: de-core-news-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.0.0/de_core_news_sm-3.0.0-py3-none-any.whl#egg=de_core_news_sm==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (8.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (57.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.4.1)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-15 11:59:45.083786: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-06-15 11:59:50.499069: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9iRJvDzO5WE",
        "outputId": "e32fd713-2c1a-4047-94f1-bc1b654f1bb9"
      },
      "source": [
        "!pip install spacy --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.7/dist-packages (3.0.6)\n",
            "Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.4)\n",
            "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.5.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.4)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.4)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jft6i-igNQfD"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "import os  # when loading file paths\n",
        "import pandas as pd  # for lookup in annotation file\n",
        "import spacy  # for tokenizer\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence  # pad batch\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XvRwxjN1UZ"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "u4PxvmSbNQfH",
        "outputId": "9b9b0d9b-5044-471a-e16e-739daa635c44"
      },
      "source": [
        "df = pd.read_csv('full_question_answer_data.txt',sep='\\t',encoding = \"ISO-8859-1\")\n",
        "new_df = df[['Answer','Question']].dropna().reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleTitle  ...   ArticleFile\n",
              "0  Abraham_Lincoln  ...  data/set3/a4\n",
              "1  Abraham_Lincoln  ...  data/set3/a4\n",
              "2  Abraham_Lincoln  ...  data/set3/a4\n",
              "3  Abraham_Lincoln  ...  data/set3/a4\n",
              "4  Abraham_Lincoln  ...  data/set3/a4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ZCHem9iiNQfK",
        "outputId": "e6d202ac-3a4e-4f6c-e512-ea6a3b741a62"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df,test_df = train_test_split(new_df,test_size=0.3)\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer</th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3364</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Does a violin have four strings?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3167</th>\n",
              "      <td>The Leningrad Philharmonic Orchestra</td>\n",
              "      <td>Give an example of the best known symphony orc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3239</th>\n",
              "      <td>26</td>\n",
              "      <td>How many letters are in the basic Latin alphabet?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Is      / ref Swahili unusual among sub-Sahara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>Because of grazing</td>\n",
              "      <td>Why do kangaroos have a wide bite?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3276</th>\n",
              "      <td>The trumpet and trombone share a roughly cylin...</td>\n",
              "      <td>Why do trumpets have a bright, loud sound?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3125</th>\n",
              "      <td>No, Portuguese is not an official language of ...</td>\n",
              "      <td>Is Portuguese an official language of Andorra?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1318</th>\n",
              "      <td>mud or sand</td>\n",
              "      <td>What are turtle eggs covered in when they incu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>Hamilton wanted to control the army differentl...</td>\n",
              "      <td>In what ways was Adams opposed by Anderw Hamil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2863</th>\n",
              "      <td>Although previously attributed to Ghirlandaio,...</td>\n",
              "      <td>Is the larger work now almost universally attr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2396 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Answer                                           Question\n",
              "3364                                                Yes                   Does a violin have four strings?\n",
              "3167               The Leningrad Philharmonic Orchestra  Give an example of the best known symphony orc...\n",
              "3239                                                 26  How many letters are in the basic Latin alphabet?\n",
              "2078                                                Yes  Is      / ref Swahili unusual among sub-Sahara...\n",
              "750                                  Because of grazing                 Why do kangaroos have a wide bite?\n",
              "...                                                 ...                                                ...\n",
              "3276  The trumpet and trombone share a roughly cylin...         Why do trumpets have a bright, loud sound?\n",
              "3125  No, Portuguese is not an official language of ...     Is Portuguese an official language of Andorra?\n",
              "1318                                        mud or sand  What are turtle eggs covered in when they incu...\n",
              "723   Hamilton wanted to control the army differentl...  In what ways was Adams opposed by Anderw Hamil...\n",
              "2863  Although previously attributed to Ghirlandaio,...  Is the larger work now almost universally attr...\n",
              "\n",
              "[2396 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "GTw_O_TiNQfL",
        "outputId": "4dbf50de-2be0-49a5-f589-b7c95d4efee6"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer</th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Did old English develop into Middle English?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2266</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Is Avogadro hailed as a founder of the atomic-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2297</th>\n",
              "      <td>die</td>\n",
              "      <td>What may happen to red fire ants if we use boi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3161</th>\n",
              "      <td>railway</td>\n",
              "      <td>How to travel to work from the city to Moscow?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>1967</td>\n",
              "      <td>When was the Six Day War?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>the Ottawa 67's</td>\n",
              "      <td>What is Ottawa's junior ice hockey team?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2308</th>\n",
              "      <td>Yes.</td>\n",
              "      <td>Do ants thrive in most ecosystems?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>yes</td>\n",
              "      <td>Was Fillmore the first U.S. President born aft...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>Carleton Ravens</td>\n",
              "      <td>What are Carleton University's athletic teams ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Do lobsters have blue blood?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1028 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Answer                                           Question\n",
              "1750              Yes       Did old English develop into Middle English?\n",
              "2266              Yes  Is Avogadro hailed as a founder of the atomic-...\n",
              "2297              die  What may happen to red fire ants if we use boi...\n",
              "3161          railway     How to travel to work from the city to Moscow?\n",
              "289              1967                          When was the Six Day War?\n",
              "...               ...                                                ...\n",
              "2015  the Ottawa 67's           What is Ottawa's junior ice hockey team?\n",
              "2308             Yes.                 Do ants thrive in most ecosystems?\n",
              "937               yes  Was Fillmore the first U.S. President born aft...\n",
              "2017  Carleton Ravens  What are Carleton University's athletic teams ...\n",
              "2872              Yes                       Do lobsters have blue blood?\n",
              "\n",
              "[1028 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k58z0MhnNQfM"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcVQIfBgNQfN"
      },
      "source": [
        "\n",
        "class DataFrameDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self,df, fields, is_test=False, **kwargs):\n",
        "        #self.df = pd.read_csv(root_dir,sep='\\t',encoding='ISO-8859-1')\n",
        "        #self.df = self.df[['Question','Answer']].dropna().reset_index()\n",
        "        examples = []\n",
        "        for i, row in df.iterrows():\n",
        "            src = row.Question\n",
        "            trg = row.Answer\n",
        "            examples.append(data.Example.fromlist([src, trg], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "      return len(ex.text)\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
        "        train_data, val_data, test_data = (None, None, None)\n",
        "        data_field = fields\n",
        "\n",
        "        if train_df is not None:\n",
        "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
        "        if val_df is not None:\n",
        "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
        "        if test_df is not None:\n",
        "            test_data = cls(test_df.copy(), data_field,True, **kwargs)\n",
        "\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5XO2kv1NQfP"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k8w7JbBNQfQ"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True\n",
        "           )\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True\n",
        "           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGa0UskaNQfR"
      },
      "source": [
        "fields = [('src',SRC), ('trg',TRG)]\n",
        "\n",
        "train_ds,test_ds= DataFrameDataset.splits(fields, train_df=train_df,test_df=test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BULwUkaoNQfS"
      },
      "source": [
        "SRC.build_vocab(train_ds, min_freq = 2)\n",
        "TRG.build_vocab(train_ds, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGkJpQs4NQfT",
        "outputId": "6e564c2a-35d4-4416-fdb9-62611fd4ecba"
      },
      "source": [
        "print(f\"Unique tokens in source  vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target  vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source  vocabulary: 2035\n",
            "Unique tokens in target  vocabulary: 1294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGGhfpH_aFjQ",
        "outputId": "00645cd2-57e1-4b09-efac-897f8deeeab9"
      },
      "source": [
        "next(iter(train_ds)),next(iter(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torchtext.legacy.data.example.Example at 0x7f3a307d0610>,\n",
              " <torchtext.legacy.data.example.Example at 0x7f395d1dc950>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPuNdstRNQfU"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SglxwRel36p"
      },
      "source": [
        "SRC.vocab.stoi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gp5Pd7El4L-"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(SRC.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9aT-5xpNQfU",
        "outputId": "8e5a3719-5b57-4534-9a11-fadaa89cb1e8"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP71TvVZNQfV"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_ds, test_ds), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device,\n",
        "    sort=False\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ_u355ENQfW"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZN20R4lNQfY"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSMkOMctNQfa"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAh0KxeqNQfd"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKektp3rNQfe",
        "outputId": "9d0c9549-1ef6-4d77-f766-8f0717f52b31"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(2035, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(1294, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=1294, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah2iPbi8NQfe",
        "outputId": "8d83c298-2062-4057-e3d7-a7f01e9d17d8"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 8,872,462 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8q91TlNQff"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0-grrzVNQfg"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTChbPmiNQfh"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "               \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421BkJ--ZiBl",
        "outputId": "4a45127d-ad57-4806-b56c-b9a6552e0210"
      },
      "source": [
        "for i, batch in enumerate(test_iterator):\n",
        "  print(i,batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 39x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 18x128 (GPU 0)]\n",
            "1 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 46x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
            "2 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 46x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 47x128 (GPU 0)]\n",
            "3 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 44x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 72x128 (GPU 0)]\n",
            "4 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 41x128 (GPU 0)]\n",
            "5 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 203x128 (GPU 0)]\n",
            "6 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
            "7 \n",
            "[torchtext.legacy.data.batch.Batch of size 128]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 52x128 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 74x128 (GPU 0)]\n",
            "8 \n",
            "[torchtext.legacy.data.batch.Batch of size 4]\n",
            "\t[.src]:[torch.cuda.LongTensor of size 17x4 (GPU 0)]\n",
            "\t[.trg]:[torch.cuda.LongTensor of size 4x4 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugQvEnUxNQfi"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        #print('Test')\n",
        "        for i, batch in enumerate(iterator):\n",
        "           \n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "           \n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gllhTKGdNQfi"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtluLYmmNQfj",
        "outputId": "e300de68-fcf8-45f1-fef0-d6f8da891fc7"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_l = []\n",
        "test_l = []\n",
        "train_ppl = []\n",
        "test_ppl = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    train_l.append(train_loss)\n",
        "    train_ppl.append(f'{math.exp(train_loss):7.3f}')\n",
        "\n",
        "    valid_loss = evaluate(model, test_iterator, criterion)\n",
        "    test_l.append(valid_loss)\n",
        "    test_ppl.append(f'{math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 2s\n",
            "\tTrain Loss: 3.945 | Train PPL:  51.659\n",
            "\t Val. Loss: 3.553 |  Val. PPL:  34.915\n",
            "Epoch: 02 | Time: 0m 2s\n",
            "\tTrain Loss: 3.881 | Train PPL:  48.483\n",
            "\t Val. Loss: 3.548 |  Val. PPL:  34.730\n",
            "Epoch: 03 | Time: 0m 2s\n",
            "\tTrain Loss: 3.882 | Train PPL:  48.531\n",
            "\t Val. Loss: 3.557 |  Val. PPL:  35.045\n",
            "Epoch: 04 | Time: 0m 2s\n",
            "\tTrain Loss: 3.847 | Train PPL:  46.835\n",
            "\t Val. Loss: 3.551 |  Val. PPL:  34.861\n",
            "Epoch: 05 | Time: 0m 2s\n",
            "\tTrain Loss: 3.872 | Train PPL:  48.028\n",
            "\t Val. Loss: 3.613 |  Val. PPL:  37.092\n",
            "Epoch: 06 | Time: 0m 2s\n",
            "\tTrain Loss: 3.790 | Train PPL:  44.255\n",
            "\t Val. Loss: 3.560 |  Val. PPL:  35.147\n",
            "Epoch: 07 | Time: 0m 2s\n",
            "\tTrain Loss: 3.806 | Train PPL:  44.980\n",
            "\t Val. Loss: 3.563 |  Val. PPL:  35.264\n",
            "Epoch: 08 | Time: 0m 2s\n",
            "\tTrain Loss: 3.808 | Train PPL:  45.059\n",
            "\t Val. Loss: 3.554 |  Val. PPL:  34.968\n",
            "Epoch: 09 | Time: 0m 2s\n",
            "\tTrain Loss: 3.727 | Train PPL:  41.537\n",
            "\t Val. Loss: 3.557 |  Val. PPL:  35.071\n",
            "Epoch: 10 | Time: 0m 2s\n",
            "\tTrain Loss: 3.676 | Train PPL:  39.482\n",
            "\t Val. Loss: 3.579 |  Val. PPL:  35.831\n",
            "Epoch: 11 | Time: 0m 2s\n",
            "\tTrain Loss: 3.716 | Train PPL:  41.084\n",
            "\t Val. Loss: 3.564 |  Val. PPL:  35.287\n",
            "Epoch: 12 | Time: 0m 2s\n",
            "\tTrain Loss: 3.669 | Train PPL:  39.207\n",
            "\t Val. Loss: 3.574 |  Val. PPL:  35.660\n",
            "Epoch: 13 | Time: 0m 2s\n",
            "\tTrain Loss: 3.635 | Train PPL:  37.901\n",
            "\t Val. Loss: 3.575 |  Val. PPL:  35.702\n",
            "Epoch: 14 | Time: 0m 2s\n",
            "\tTrain Loss: 3.582 | Train PPL:  35.943\n",
            "\t Val. Loss: 3.605 |  Val. PPL:  36.773\n",
            "Epoch: 15 | Time: 0m 2s\n",
            "\tTrain Loss: 3.568 | Train PPL:  35.455\n",
            "\t Val. Loss: 3.597 |  Val. PPL:  36.473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "M-dTOEYQNQfk",
        "outputId": "3b6cd8d3-2ee4-451d-a9d5-c9f916f6bd9e"
      },
      "source": [
        "#  training loss vs validation Accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1,16)\n",
        "plt.plot(epochs, train_l, 'g', label='Training loss')\n",
        "plt.plot(epochs, test_l, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erFIQjCgjS-_"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./tut1-model.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCTsAP79mUzw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}